{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from random import seed, randrange\n",
    "from csv import reader\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9  ...      51      52      53      54      55      56      57      58  \\\n",
       "0  0.2111 ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084  0.0090   \n",
       "1  0.2872 ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049  0.0052   \n",
       "2  0.6194 ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164  0.0095   \n",
       "3  0.1264 ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044  0.0040   \n",
       "4  0.4459 ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048  0.0107   \n",
       "\n",
       "       59  60  \n",
       "0  0.0032   R  \n",
       "1  0.0044   R  \n",
       "2  0.0078   R  \n",
       "3  0.0117   R  \n",
       "4  0.0094   R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonar = pd.read_csv('sonar.csv', header = None)\n",
    "sonar.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating Splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a decision tree, split points are chosen by finding the attribute and the value of that attribute that results in the lowest cost.\n",
    "\n",
    "Gini is a measure of how often a randomly chosen element from the set would be incorrectly labeled if it was randomly labeled according to the distribution of labels in the subset. A Gini score gives an idea of how good a split is by how mixed the classes are in the two groups created by the split. \n",
    "\n",
    "For classification problems, this cost function is often the **Gini index**, that calculates the purity of the groups of data created by the split point, whereas the worst case split that results in 50/50 classes in each group results in a Gini score of 1.0.\n",
    "\n",
    "When building a binary tree, calculate it for every row and split the data accordingly and repeat this process recursively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree & RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load a csv file into list of lists - csv_reader creats an object to be read row by row \n",
    "\n",
    "def load_csv(filename):\n",
    "    dataset = list()\n",
    "    with open(filename, 'r') as file:\n",
    "        csv_reader = reader(file)\n",
    "        for row in csv_reader:\n",
    "            if not row:\n",
    "                continue\n",
    "            dataset.append(row)\n",
    "            \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert string feature value to float - entries for each row are string value, removing the white sapce before and after the string\n",
    "# and convert the entries to float values \n",
    "# str.strip() Returns a copy of the string with leading and trailing characters removed\n",
    "\n",
    "def str_column_to_float(dataset, column):\n",
    "    for row in dataset:\n",
    "        row[column] = float(row[column].strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert string label value to integer - class label is documented in the last column\n",
    "\n",
    "def str_column_to_int(dataset, column):\n",
    "    class_values = [row[column] for row in dataset]\n",
    "    unique = set(class_values)\n",
    "\n",
    "    lookup = dict()\n",
    "    # create mapping dict - string label to integer\n",
    "    for i, value in enumerate(unique):\n",
    "        lookup[value] = i\n",
    "        \n",
    "    for row in dataset:\n",
    "        # dataset.replace(mapping)\n",
    "        row[column] = lookup[row[column]]\n",
    "    \n",
    "    return lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split data into k folds\n",
    "# pop removes and returns the last item in the list\n",
    "\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "    dataset_split = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset)/ n_folds)\n",
    "    \n",
    "    for i in range(n_folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "        \n",
    "    return dataset_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate accuracy percentage\n",
    "\n",
    "def accuracy_metric(actual, predicted):\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "     \n",
    "    return correct/ float(len(actual)) * 100\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CV in model selection \n",
    "\n",
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "    \n",
    "    folds = cross_validation_split(dataset, n_folds)\n",
    "    scores = list()\n",
    "    for fold in folds:\n",
    "        # train_set is a list of K lists of folds \n",
    "        train_set = list(folds)\n",
    "        train_set.remove(fold)\n",
    "        # sum list of lists and empty list gives converts the list of lists to one list\n",
    "        train_set = sum(train_set, [])\n",
    "        \n",
    "        test_set = list()\n",
    "        for row in fold:\n",
    "            row_copy = list(row)\n",
    "            test_set.append(row_copy)\n",
    "            row_copy[-1] = None\n",
    "            \n",
    "        predicted = algorithm(train_set, test_set, *args)\n",
    "        actual = [row[-1] for row in fold]\n",
    "        accuracy = accuracy_metric(actual, predicted)\n",
    "        scores.append(accuracy)\n",
    "        \n",
    "    return scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split dataset based on an attribute index and an attribute value \n",
    "\n",
    "def test_split(index, value, dataset):\n",
    "    left, right = list(), list()\n",
    "    for row in dataset:\n",
    "        if row[index] < value:\n",
    "            left.append(row)\n",
    "        else:\n",
    "            right.append(row)\n",
    "            \n",
    "    return left, right "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision trees "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**test_split** \n",
    "- splits the dataset by using the given variable index and split value\n",
    "- returns the splitted dataset as two lists \n",
    "\n",
    "**gni_index** \n",
    "- calculates the gini index for given two groups of data and their class labels \n",
    "\n",
    "**get_split** \n",
    "- finds the best split index and value by lopping through all those combination in the given dataset, i.e. using test_split on all combinations  \n",
    "- calculates Gini index for the newly splitted groups\n",
    "- if it is smaller than the previous one, update the dictionary that contains split index, value and groups \n",
    "- and returns the selected split index and value together with the resulting groups as two lists in a dictionary\n",
    "\n",
    "**split(node, max_depth, min_size, n_features, depth)**\n",
    "- splits the returned groups from get_split to two child nodes - node['left'] and node['right']\n",
    "- and checks if the split can continue, if it can use get_split and split functions to continue the split, returns nothing \n",
    "- if it cannot, calculate the majority vote in that node and replace node['left'] and node['right'] with the voting results \n",
    "\n",
    "**build_tree** \n",
    "- starts from using get_split to create the initiall node expressed in a dictionary\n",
    "- and continues the split using get_split and split as in the two blocks above \n",
    "- returns the dictionary of splits "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gini and entropy\n",
    "\n",
    "http://www.learnbymarketing.com/481/decision-tree-flavors-gini-info-gain/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate gini index for a given split results(attribute, value, child groups)\n",
    "\n",
    "def gini_index(groups, classes):\n",
    "    \n",
    "    # count total number of samples in the two child groups \n",
    "    n_instances = float(sum([len(group) for group in groups]))\n",
    "    \n",
    "    # sum weighted gini index for each group\n",
    "    gini = 0\n",
    "    for group in groups:\n",
    "        size = float(len(group))\n",
    "        # avoid using zero as denominator \n",
    "        if size == 0:\n",
    "            continue\n",
    "        score = 0\n",
    "        \n",
    "        # score the split based on the score for the resulting class -- 1 - sumi (p_i **2)\n",
    "        for class_val in classes:\n",
    "            p = [row[-1] for row in group].count(class_val)/ size\n",
    "            score += p* p\n",
    "            # weight group score by its relatvie size \n",
    "            gini += (1 - score) * (size/ n_instances)\n",
    "\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select the best split point for a dataset and return the index, value and child groups \n",
    "\n",
    "def get_split(dataset, n_features):\n",
    "    \n",
    "    class_values = list(set(row[-1] for row in dataset)) # collect all the class labels in training dataset \n",
    "    b_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
    "    \n",
    "    features = list()\n",
    "    while len(features) < n_features:\n",
    "        # get all the feature index\n",
    "        index = randrange(len(dataset[0]) - 1)\n",
    "        if index not in features:\n",
    "            features.append(index)\n",
    "    \n",
    "    # gready search through all the feature index and value combination\n",
    "    for index in features:\n",
    "        for row in dataset:\n",
    "            # split first then calcualte Gini\n",
    "            groups = test_split(index, row[index], dataset)\n",
    "            gini = gini_index(groups, class_values)\n",
    "            # update split when gini is smaller \n",
    "            if gini < b_score:\n",
    "                b_index, b_value, b_score, b_groups = index, row[index], gini, groups\n",
    "\n",
    "    return {'index': b_index, 'value': b_value, 'groups': b_groups}\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# returns a terminal node value - majority vote\n",
    "\n",
    "def to_terminal(group):\n",
    "    outcomes = [row[-1] for row in group]\n",
    "    \n",
    "    return max(set(outcomes), key = outcomes.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create child splits for a node or make terminal if conditions are met \n",
    "\n",
    "def split(node, max_depth, min_size, n_features, depth):\n",
    "    \n",
    "    print ({node['index'], node['value']})\n",
    "\n",
    "    # create child splits for a node\n",
    "    left, right = node['groups']\n",
    "    # change 'groups' to 'left' and 'right'\n",
    "    del(node['groups'])\n",
    "    \n",
    "    # check for a no split - when all the feature index and value combination has been checked \n",
    "    if not left or right:\n",
    "        node['left'] = node['right'] = to_terminal(left + right)\n",
    "        return\n",
    "    \n",
    "    # check for max depth\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "        return\n",
    "    \n",
    "    # process left child\n",
    "    if len(left) <= min_size:\n",
    "        node['left'] = to_terminal(left)\n",
    "    else:\n",
    "        node['left'] = get_split(left, n_features)\n",
    "        split(node['left'], max_depth, min_size, n_features, depth + 1)\n",
    "       \n",
    "    # process right child\n",
    "    if len(right) <= min_size:\n",
    "        node['right'] = to_terminal(right)\n",
    "    else: \n",
    "        node['right'] = get_split(right, n_features)\n",
    "        split(node['right'], max_depth, min_size, n_features, depth + 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build a decision tree\n",
    "\n",
    "def build_tree(train, max_depth, min_size, n_features):\n",
    "    # find the first best split and continue the split \n",
    "    root = get_split(train, n_features)\n",
    "    \n",
    "    # this root is passed as a node for the following splits and it is a dictionary of selected split index, value and groups \n",
    "    split(root, max_depth, min_size, n_features, 1)\n",
    "    \n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make a prediction with a decision tree\n",
    "\n",
    "def predict(node, row):\n",
    "    # predictions are made at the end nodes \n",
    "    # returns the predicted group the row belongs to need to use max(group) to find the class label later \n",
    "    \n",
    "    if row[node['index']] < node['value']:\n",
    "    # due to row[index] < value from test_split    \n",
    "        \n",
    "        # isinstance Returns a Boolean stating whether the object is an instance or subclass of another object\n",
    "        # when conditions are not met, splits have to continue then the returns from split function is a dictionary \n",
    "        # of the following split results instead of that when terminate function is called \n",
    "        if isinstance(node['left'], dict): \n",
    "            return predict(node['left'], row)\n",
    "        else:\n",
    "            return node['left'] # left group\n",
    "        \n",
    "    else:\n",
    "        if isinstance(node['right'], dict):\n",
    "            return predict(node['right'], row)\n",
    "        else:\n",
    "            return node['right']\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a random subsample from the dataset with replacement \n",
    "\n",
    "def subsample(dataset, ratio):\n",
    "    sample = list()\n",
    "    n_sample = round(len(dataset)* ratio)\n",
    "    while len(sample) < n_sample:\n",
    "        index = randrange(len(dataset))\n",
    "        sample.append(dataset[index])\n",
    "        \n",
    "    return sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make a prediction with a list of bagged trees \n",
    "\n",
    "def baggging_predict(trees, row):\n",
    "    predictions = [predict(tree, row) for tree in trees]\n",
    "    \n",
    "    return max(set(predictions), key = predictions.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# random forest algorithm\n",
    "\n",
    "def random_forest(train, test, max_depth, min_size, sample_size, n_trees, n_features):\n",
    "    \n",
    "    trees = list()\n",
    "    for i in range(n_trees):\n",
    "        sample = subsample(train, sample_size)\n",
    "        \n",
    "        # build_tree returns the tree definition dictionary {'index': b_index, 'value': b_value, 'groups': b_groups}\n",
    "        tree = build_tree(sample, max_depth, min_size, n_features)\n",
    "        trees.append(tree)\n",
    "        \n",
    "    # tree['index']\n",
    "    predictions = [baggging_predict(trees, row) for row in test]\n",
    "    \n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trees: 5\n",
      "Scores: [48.78048780487805, 21.951219512195124, 48.78048780487805, 31.70731707317073, 53.65853658536586]\n",
      "Mean Accuracy: 40.976%\n",
      "Trees: 100\n",
      "Scores: [65.85365853658537, 51.21951219512195, 56.09756097560976, 41.46341463414634, 51.21951219512195]\n",
      "Mean Accuracy: 53.171%\n",
      "Trees: 1000\n",
      "Scores: [36.58536585365854, 53.65853658536586, 60.97560975609756, 34.146341463414636, 46.34146341463415]\n",
      "Mean Accuracy: 46.341%\n"
     ]
    }
   ],
   "source": [
    "# test the random forest algorithm\n",
    "\n",
    "seed(2)\n",
    "filename = 'sonar.csv'\n",
    "dataset = load_csv(filename)\n",
    "\n",
    "# convert string attributes to integers \n",
    "for i in range(0, len(dataset[0]) - 1):\n",
    "    str_column_to_float(dataset, i)\n",
    "    \n",
    "# convert class column to integers \n",
    "str_column_to_int(dataset, len(dataset[0]) - 1)\n",
    "\n",
    "# algorithm evaluation \n",
    "n_folds = 5\n",
    "max_depth = 10\n",
    "min_size = 1\n",
    "sample_size = 1\n",
    "n_features = int(sqrt(len(dataset[0]) - 1))\n",
    "\n",
    "for n_trees in [5, 100, 1000]:\n",
    "    scores = evaluate_algorithm(dataset, random_forest, n_folds, max_depth, min_size, sample_size, n_trees, n_features)\n",
    "    print('Trees: %d' % n_trees)\n",
    "    print('Scores: %s' % scores)\n",
    "    print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.203, 43}\n",
      "{0.2128, 10}\n",
      "{0.9085, 27}\n",
      "{0.1556, 11}\n",
      "{0.1645, 12}\n",
      "{0.161, 10}\n",
      "{0.1989, 10}\n",
      "{0.2154, 11}\n",
      "{0.2087, 11}\n",
      "{0.1171, 5}\n"
     ]
    }
   ],
   "source": [
    "# parameters \n",
    "n_folds = 5\n",
    "max_depth = 1\n",
    "min_size = 1\n",
    "sample_size = 1\n",
    "# 7 features\n",
    "n_features = int(sqrt(len(dataset[0]) - 1))\n",
    "n_trees = 5\n",
    "\n",
    "\n",
    "# train test split \n",
    "folds = cross_validation_split(dataset, n_folds)\n",
    "\n",
    "\n",
    "\n",
    "train_set = list(folds)\n",
    "train_set.remove(folds[0])\n",
    "# sum list of lists and empty list gives converts the list of lists to one list\n",
    "train_set = sum(train_set, [])\n",
    "\n",
    "test_set = list()\n",
    "for row in folds[0]:\n",
    "    row_copy = list(row)\n",
    "    test_set.append(row_copy)\n",
    "    row_copy[-1] = None\n",
    "    \n",
    "train = train_set\n",
    "test = test_set\n",
    "\n",
    "\n",
    "\n",
    "root = random_forest(train, test, max_depth, min_size, sample_size, n_trees, n_features)\n",
    "\n",
    "# random_forest(train, test, max_depth, min_size, sample_size, n_trees, n_features)\n",
    "trees = list()\n",
    "for i in range(n_trees):\n",
    "    sample = subsample(train, sample_size)\n",
    "\n",
    "    # build_tree returns the tree definition dictionary {'index': b_index, 'value': b_value, 'groups': b_groups}\n",
    "    tree = build_tree(sample, max_depth, min_size, n_features)\n",
    "    trees.append(tree)\n",
    "\n",
    "# tree['index']\n",
    "predictions = [baggging_predict(trees, row) for row in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': 10, 'left': 1, 'right': 1, 'value': 0.161}"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'index': 10, 'left': 1, 'right': 1, 'value': 0.161},\n",
       " {'index': 10, 'left': 0, 'right': 0, 'value': 0.1989},\n",
       " {'index': 11, 'left': 0, 'right': 0, 'value': 0.2154},\n",
       " {'index': 11, 'left': 0, 'right': 0, 'value': 0.2087},\n",
       " {'index': 5, 'left': 1, 'right': 1, 'value': 0.1171}]"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
