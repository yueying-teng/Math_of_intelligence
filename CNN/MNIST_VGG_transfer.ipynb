{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/keras-team/keras/blob/master/examples/mnist_transfer_cnn.py\n",
    "\n",
    "** Transfer learning toy example**\n",
    "\n",
    "- Train a simple convnet on the MNIST dataset the first 5 digits [0...4].\n",
    "- Freeze convolutional layers and fine-tune dense/output layers for the classification for the rest digits [5...9].\n",
    "\n",
    "Get to 99.8% test accuracy after 5 epochs for the first five digits classifier and 99.2% for the last five digits after transfer + fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yueyingteng/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function \n",
    "\n",
    "import datetime\n",
    "import keras \n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten \n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "num_classes = 5\n",
    "\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions \n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# number of convolutional filters to use \n",
    "filters = 32\n",
    "\n",
    "# convolutional kernel size \n",
    "kernel_size = 3\n",
    "\n",
    "# size of pooling area for max pooling\n",
    "pool_size = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    # tf backend has K.image_data_format() == 'channels_last'\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train, test, num_classes):\n",
    "    \n",
    "    # change input data size so they match tensorflow requirements\n",
    "    x_train = train[0].reshape((train[0].shape[0],) + input_shape)\n",
    "    x_test = test[0].reshape((test[0].shape[0],) + input_shape)\n",
    "    \n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    # normalization like \n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    \n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "    \n",
    "    # one hot encode class vectors \n",
    "    y_train = keras.utils.to_categorical(train[1], num_classes)\n",
    "    y_test = keras.utils.to_categorical(test[1], num_classes)\n",
    "    \n",
    "    # compile for training\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adadelta', metrics = ['accuracy'])\n",
    "    \n",
    "    t = now()\n",
    "    model.fit(x_train, y_train, batch_size = batch_size, epochs = epochs, verbose = 1, validation_data = (x_test, y_test))\n",
    "    \n",
    "    print('Training time: %s' % (now() - t))\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30596, 28, 28)\n",
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "# create two datasets one with digits below 5 and the other above\n",
    "\n",
    "x_train_lt5 = x_train[y_train < 5]\n",
    "y_train_lt5 = y_train[y_train < 5]\n",
    "x_test_lt5 = x_test[y_test < 5]\n",
    "y_test_lt5 = y_test[y_test < 5]\n",
    "\n",
    "x_train_gte5 = x_train[y_train >= 5]\n",
    "y_train_gte5 = y_train[y_train >= 5] - 5\n",
    "x_test_gte5 = x_test[y_test >= 5]\n",
    "y_test_gte5 = y_test[y_test >= 5] - 5\n",
    "\n",
    "print(x_train_lt5.shape)\n",
    "print(x_train_lt5[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define two groups of layers: feature(convolutions) and classification(dense)\n",
    "\n",
    "feature_layers = [Conv2D(filters, kernel_size, padding = 'valid', input_shape = input_shape),\n",
    "                 Activation('relu'),\n",
    "                 Conv2D(filters, kernel_size),\n",
    "                 Activation('relu'),\n",
    "                 MaxPooling2D(pool_size = pool_size),\n",
    "                 Dropout(0.25),\n",
    "                 Flatten()]\n",
    "\n",
    "\n",
    "classification_layers = [Dense(128),\n",
    "                         Activation('relu'),\n",
    "                         Dropout(0.5), \n",
    "                         Dense(num_classes), \n",
    "                         Activation('softmax')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the complete model\n",
    "\n",
    "model = Sequential(feature_layers + classification_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (30596, 28, 28, 1)\n",
      "30596 train samples\n",
      "5139 test samples\n",
      "Train on 30596 samples, validate on 5139 samples\n",
      "Epoch 1/5\n",
      "30596/30596 [==============================] - 47s 2ms/step - loss: 0.0189 - acc: 0.9945 - val_loss: 0.0087 - val_acc: 0.9967\n",
      "Epoch 2/5\n",
      "30596/30596 [==============================] - 46s 2ms/step - loss: 0.0158 - acc: 0.9955 - val_loss: 0.0059 - val_acc: 0.9975\n",
      "Epoch 3/5\n",
      "30596/30596 [==============================] - 46s 2ms/step - loss: 0.0140 - acc: 0.9959 - val_loss: 0.0049 - val_acc: 0.9981\n",
      "Epoch 4/5\n",
      "30596/30596 [==============================] - 46s 2ms/step - loss: 0.0123 - acc: 0.9961 - val_loss: 0.0046 - val_acc: 0.9981\n",
      "Epoch 5/5\n",
      "30596/30596 [==============================] - 48s 2ms/step - loss: 0.0116 - acc: 0.9962 - val_loss: 0.0039 - val_acc: 0.9984\n",
      "Training time: 0:03:53.497734\n",
      "Test score: 0.0038775279982246635\n",
      "Test accuracy: 0.9984432769021211\n"
     ]
    }
   ],
   "source": [
    "# train model for 5-digit clasification [0...4]\n",
    "\n",
    "train_model(model, (x_train_lt5, y_train_lt5), (x_test_lt5, y_test_lt5), num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze feature layers and rebuild the model for a different classification task [5...9]\n",
    "\n",
    "for l in feature_layers:\n",
    "    l.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (29404, 28, 28, 1)\n",
      "29404 train samples\n",
      "4861 test samples\n",
      "Train on 29404 samples, validate on 4861 samples\n",
      "Epoch 1/5\n",
      "29404/29404 [==============================] - 18s 614us/step - loss: 0.2260 - acc: 0.9362 - val_loss: 0.0484 - val_acc: 0.9833\n",
      "Epoch 2/5\n",
      "29404/29404 [==============================] - 18s 602us/step - loss: 0.0700 - acc: 0.9785 - val_loss: 0.0327 - val_acc: 0.9895\n",
      "Epoch 3/5\n",
      "29404/29404 [==============================] - 19s 631us/step - loss: 0.0531 - acc: 0.9836 - val_loss: 0.0250 - val_acc: 0.9924\n",
      "Epoch 4/5\n",
      "29404/29404 [==============================] - 18s 597us/step - loss: 0.0422 - acc: 0.9869 - val_loss: 0.0240 - val_acc: 0.9918\n",
      "Epoch 5/5\n",
      "29404/29404 [==============================] - 18s 598us/step - loss: 0.0387 - acc: 0.9877 - val_loss: 0.0218 - val_acc: 0.9932\n",
      "Training time: 0:01:29.605572\n",
      "Test score: 0.0218465242016587\n",
      "Test accuracy: 0.9932112732901786\n"
     ]
    }
   ],
   "source": [
    "# tranfer - train dense layers for new classification task [5...9]. training using new task data \n",
    "\n",
    "train_model(model, (x_train_gte5, y_train_gte5), (x_test_gte5, y_test_gte5), num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transfer learning with VGG and MNIST\n",
    "\n",
    "- **retrain output dense layer only/ using VGG as feature extractor(bottleneck feature)** The output layer in a vgg16 is a softmax activation with 1000 categories. Remove this layer and replace it with a softmax layer of 10 categories. VGG architectue is changed in this case.\n",
    "\n",
    "- **freeze the weights of the first few layers** the first few layers capture universal features like curves and edges, which are also relevant to the new problem. VGG architectue is not changed in this case, but image size is **different** from which (224 x 224) VGG is trained on. Easier to retrain on the Dense layer Repalced VGG16."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16 as feature extractor & retrain the replaced output Dense layer ONLY\n",
    "\n",
    "### VGG16 has requirement on minimium input size, which is cannot be met by MNIST input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain output dense layer only\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load VGG16 model weights\n",
    "\n",
    "model = VGG16(weights = 'imagenet', include_top = False)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check which backend is used and reshape the data to match Keras' expectation \n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# VGG is trained on color images - repeat grayscale image over three color channels\n",
    "# np.repeat - if ``axis = 0`` it will be the first dimension and if ``axis = -1`` it will be the last dimension.\n",
    "# expand channels for both training and testing images \n",
    "\n",
    "train_color_channel = []\n",
    "for i in range(x_train.shape[0]):\n",
    "    train_color_channel.append(np.repeat(x_train[i], 3, axis= -1))\n",
    "    \n",
    "test_color_channel = []\n",
    "for i in range(x_test.shape[0]):\n",
    "    test_color_channel.append(np.repeat(x_test[i], 3, axis= -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 3)\n",
      "number of train samples:  60000\n",
      "number of test samples:  10000\n"
     ]
    }
   ],
   "source": [
    "# data normalization \n",
    "\n",
    "x_train = np.array(train_color_channel).astype('float32')\n",
    "x_test = np.array(test_color_channel).astype('float32')\n",
    "# normalization like \n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('number of train samples: ', x_train.shape[0])\n",
    "print('number of test samples: ', x_test.shape[0])\n",
    "\n",
    "\n",
    "# one hot encode class vectors\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features from training and testing data using pretrained VGG16 without top \n",
    "\n",
    "now = datetime.datetime.now\n",
    "t = now()\n",
    "\n",
    "feature_train = model.predict(x_train)\n",
    "feature_test = model.predict(x_test)\n",
    "\n",
    "print('Feature extracting time: %s' % (now() - t))\n",
    "\n",
    "print(feature_train.shape)\n",
    "print(feature_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the classification layer and train this layer only using MNIST data \n",
    "\n",
    "new_model = Sequential()\n",
    "# new_model.add(model)\n",
    "new_model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "layers = new_model.layers\n",
    "for layer in layers[: -1]: \n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rehshape features extracted for training and testing data to be suitable for model fitting\n",
    "\n",
    "feature_train = feature_train.reshape(feature_train.shape[0], feature_train.shape[-1])\n",
    "feature_test = feature_test.reshape(feature_test.shape[0], feature_test.shape[-1])\n",
    "\n",
    "# model compile \n",
    "new_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# model fitting \n",
    "# - x_train in the original model.fit has to be of (num_exampels, nrows, ncols, nchannels)\n",
    "# - now only the Dense layer is trained, x_trian's size should match this requiremnt \n",
    "\n",
    "new_model.fit(feature_train, y_train, batch_size = batch_size, epochs = epochs, validation_data = (feature_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trained model weights \n",
    "\n",
    "new_model.save_weights('vgg_feature_extractor.h5')\n",
    "\n",
    "new_model.load_weights('vgg_feature_extractor.h5')\n",
    "\n",
    "new_model.evaluate(feature_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
